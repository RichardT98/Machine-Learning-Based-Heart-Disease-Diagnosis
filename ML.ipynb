{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all packages required to perform various classifications\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "clevelanddata = pd.read_csv('cleveland_cleaned.csv') \n",
    "statlogdata = pd.read_csv('statlog_cleaned.csv')\n",
    "combineddata = pd.read_csv('combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-japan",
   "metadata": {},
   "source": [
    "***CLEVELAND:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "parliamentary-greek",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    160\n",
       "2    137\n",
       "Name: absence or presence of heart disease, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleveland Dataset: checking the distribution of heart disease variable where 1 means absence and 2 means presence of heart disease\n",
    "clevelanddata['absence or presence of heart disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "referenced-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the features and the targets for cleveland\n",
    "X = clevelanddata.drop(columns='absence or presence of heart disease', axis=1)\n",
    "Y = clevelanddata['absence or presence of heart disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parallel-aviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      2\n",
      "2      2\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "292    2\n",
      "293    2\n",
      "294    2\n",
      "295    2\n",
      "296    2\n",
      "Name: absence or presence of heart disease, Length: 297, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moving-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
      "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
      "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
      "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
      "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
      "292  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
      "293  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
      "294  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
      "295  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
      "296  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
      "\n",
      "     slope   ca  thal  \n",
      "0      3.0  0.0   6.0  \n",
      "1      2.0  3.0   3.0  \n",
      "2      2.0  2.0   7.0  \n",
      "3      3.0  0.0   3.0  \n",
      "4      1.0  0.0   3.0  \n",
      "..     ...  ...   ...  \n",
      "292    2.0  0.0   7.0  \n",
      "293    2.0  0.0   7.0  \n",
      "294    2.0  2.0   7.0  \n",
      "295    2.0  1.0   7.0  \n",
      "296    2.0  1.0   3.0  \n",
      "\n",
      "[297 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "international-paradise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 13) (237, 13) (60, 13)\n"
     ]
    }
   ],
   "source": [
    "# split to training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "viral-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR - Accuracy on Training data:  0.8270042194092827\n",
      "LR - F1 score on Training data:  0.8487084870848707\n",
      "LR - Accuracy on Testing data:  0.9166666666666666\n",
      "LR - F1 score on Testing data:  0.912280701754386\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"LR - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"LR - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"LR - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"LR - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "common-african",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy on Training data:  0.8312236286919831\n",
      "SVM - F1 score on Training data:  0.849624060150376\n",
      "SVM - Accuracy on Testing data:  0.8833333333333333\n",
      "SVM - F1 score on Testing data:  0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# define the SVM model with best parameters found via GridSearch\n",
    "svm_model = SVC(kernel='linear', C=10, class_weight='balanced')\n",
    "\n",
    "# training the model with training data\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = svm_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"SVM - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"SVM - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = svm_model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"SVM - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"SVM - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "viral-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB - Accuracy on Training data:  0.8438818565400844\n",
      "NB - F1 score on Training data:  0.8634686346863468\n",
      "NB - Accuracy on Testing data:  0.9166666666666666\n",
      "NB - F1 score on Testing data:  0.912280701754386\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "# define the Naive Bayes model with best hyperparameters found via GridSearch\n",
    "nb_model = GaussianNB(var_smoothing=1e-09)\n",
    "\n",
    "# training the model with training data\n",
    "nb_model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = nb_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"NB - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"NB - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = nb_model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"NB - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"NB - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pending-observation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN - Accuracy on Training data:  0.8607594936708861\n",
      "ANN - F1 score on Training data:  0.8754716981132077\n",
      "ANN - Accuracy on Testing data:  0.8833333333333333\n",
      "ANN - F1 score on Testing data:  0.8813559322033899\n"
     ]
    }
   ],
   "source": [
    "# ANN\n",
    "# define the ANN model with best hyperparameters found via GridSearch\n",
    "model = MLPClassifier(max_iter=10000,hidden_layer_sizes=(15, 10), activation='logistic', alpha=0.01)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"ANN - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"ANN - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"ANN - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"ANN - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "combined-wound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Accuracy on Training data:  0.9873417721518988\n",
      "RF - F1 score on Training data:  0.9886792452830188\n",
      "RF - Accuracy on Testing data:  0.9166666666666666\n",
      "RF - F1 score on Testing data:  0.9152542372881356\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "# define the RF model with best hyperparameters\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"RF - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"RF - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"RF - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"RF - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "willing-marble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN - Accuracy on Training data:  0.7130801687763713\n",
      "k-NN - F1 score on Training data:  0.7106230160715576\n",
      "k-NN - Accuracy on Testing data:  0.65\n",
      "k-NN - F1 score on Testing data:  0.6495137538205057\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# Performing k-Nearest Neighbors model best hyperparameters found via GridSearch\n",
    "model = KNeighborsClassifier(n_neighbors=11, p=2, weights='uniform')\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print(\"k-NN - Accuracy on Training data: \", training_data_accuracy)\n",
    "\n",
    "training_f1_score = f1_score(Y_train, X_train_prediction, average='weighted')\n",
    "print(\"k-NN - F1 score on Training data: \", training_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "\n",
    "testing_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print(\"k-NN - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "\n",
    "testing_f1_score = f1_score(Y_test, X_test_prediction, average='weighted')\n",
    "print(\"k-NN - F1 score on Testing data: \", testing_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-research",
   "metadata": {},
   "source": [
    "***STATLOG:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "front-likelihood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    150\n",
       "2    120\n",
       "Name: absence or presence of heart disease, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statlog Dataset: checking the distribution of heart disease variable where 1 means absence and 2 means presence of heart disease\n",
    "statlogdata['absence or presence of heart disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "foreign-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the features and the targets for statlog\n",
    "X = statlogdata.drop(columns='absence or presence of heart disease', axis=1)\n",
    "Y = statlogdata['absence or presence of heart disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "million-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2\n",
      "1      1\n",
      "2      2\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "265    1\n",
      "266    1\n",
      "267    1\n",
      "268    1\n",
      "269    2\n",
      "Name: absence or presence of heart disease, Length: 270, dtype: int64\n",
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    70.0  1.0  4.0     130.0  322.0  0.0      2.0    109.0    0.0      2.4   \n",
      "1    67.0  0.0  3.0     115.0  564.0  0.0      2.0    160.0    0.0      1.6   \n",
      "2    57.0  1.0  2.0     124.0  261.0  0.0      0.0    141.0    0.0      0.3   \n",
      "3    64.0  1.0  4.0     128.0  263.0  0.0      0.0    105.0    1.0      0.2   \n",
      "4    74.0  0.0  2.0     120.0  269.0  0.0      2.0    121.0    1.0      0.2   \n",
      "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
      "265  52.0  1.0  3.0     172.0  199.0  1.0      0.0    162.0    0.0      0.5   \n",
      "266  44.0  1.0  2.0     120.0  263.0  0.0      0.0    173.0    0.0      0.0   \n",
      "267  56.0  0.0  2.0     140.0  294.0  0.0      2.0    153.0    0.0      1.3   \n",
      "268  57.0  1.0  4.0     140.0  192.0  0.0      0.0    148.0    0.0      0.4   \n",
      "269  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
      "\n",
      "     slope   ca  thal  \n",
      "0      2.0  3.0   3.0  \n",
      "1      2.0  0.0   7.0  \n",
      "2      1.0  0.0   7.0  \n",
      "3      2.0  1.0   7.0  \n",
      "4      1.0  1.0   3.0  \n",
      "..     ...  ...   ...  \n",
      "265    1.0  0.0   7.0  \n",
      "266    1.0  0.0   7.0  \n",
      "267    2.0  0.0   3.0  \n",
      "268    2.0  0.0   6.0  \n",
      "269    2.0  3.0   3.0  \n",
      "\n",
      "[270 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(Y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "given-semester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 13) (216, 13) (54, 13)\n"
     ]
    }
   ],
   "source": [
    "# split to training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dramatic-cleaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR - Accuracy on Training data:  0.8564814814814815\n",
      "LR - F1 score on Training data:  0.8724279835390946\n",
      "LR - Accuracy on Testing data:  0.8518518518518519\n",
      "LR - F1 score on Testing data:  0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"LR - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"LR - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"LR - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"LR - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "meaning-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy on Training data:  0.8703703703703703\n",
      "SVM - F1 score on Training data:  0.8823529411764707\n",
      "SVM - Accuracy on Testing data:  0.7962962962962963\n",
      "SVM - F1 score on Testing data:  0.8358208955223881\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# define the SVM model with best parameters found via GridSearch\n",
    "svm_model = SVC(kernel='linear', C=10, class_weight='balanced')\n",
    "\n",
    "# training the model with training data\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = svm_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"SVM - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"SVM - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = svm_model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"SVM - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"SVM - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fatal-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB - Accuracy on Training data:  0.8564814814814815\n",
      "NB - F1 score on Training data:  0.8680851063829789\n",
      "NB - Accuracy on Testing data:  0.8703703703703703\n",
      "NB - F1 score on Testing data:  0.8955223880597014\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "# define the Naive Bayes model with best hyperparameters found via GridSearch\n",
    "nb_model = GaussianNB(var_smoothing=1e-09)\n",
    "\n",
    "# training the model with training data\n",
    "nb_model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = nb_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"NB - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"NB - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = nb_model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"NB - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"NB - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "behavioral-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN - Accuracy on Training data:  0.8472222222222222\n",
      "ANN - F1 score on Training data:  0.8663967611336033\n",
      "ANN - Accuracy on Testing data:  0.8518518518518519\n",
      "ANN - F1 score on Testing data:  0.8787878787878787\n"
     ]
    }
   ],
   "source": [
    "# ANN\n",
    "# define the ANN model with best hyperparameters found via GridSearch\n",
    "model = MLPClassifier(max_iter=10000,hidden_layer_sizes=(15, 10), activation='logistic', alpha=0.01)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"ANN - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"ANN - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"ANN - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"ANN - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "applicable-nudist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Accuracy on Training data:  0.9861111111111112\n",
      "RF - F1 score on Training data:  0.9873417721518987\n",
      "RF - Accuracy on Testing data:  0.8333333333333334\n",
      "RF - F1 score on Testing data:  0.8615384615384615\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "# define the RF model with best hyperparameters\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"RF - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"RF - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"RF - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"RF - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "growing-situation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN - Accuracy on Training data:  0.7222222222222222\n",
      "k-NN - F1 score on Training data:  0.7204009674505348\n",
      "k-NN - Accuracy on Testing data:  0.6481481481481481\n",
      "k-NN - F1 score on Testing data:  0.6507253678512837\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# Performing k-Nearest Neighbors model best hyperparameters found via GridSearch\n",
    "model = KNeighborsClassifier(n_neighbors=11, p=2, weights='uniform')\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print(\"k-NN - Accuracy on Training data: \", training_data_accuracy)\n",
    "\n",
    "training_f1_score = f1_score(Y_train, X_train_prediction, average='weighted')\n",
    "print(\"k-NN - F1 score on Training data: \", training_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "\n",
    "testing_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print(\"k-NN - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "\n",
    "testing_f1_score = f1_score(Y_test, X_test_prediction, average='weighted')\n",
    "print(\"k-NN - F1 score on Testing data: \", testing_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-material",
   "metadata": {},
   "source": [
    "***COMBINED:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fifteen-customer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    310\n",
       "2    257\n",
       "Name: absence or presence of heart disease, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined Dataset: checking the distribution of heart disease variable where 1 means absence and 2 means presence of heart disease\n",
    "combineddata['absence or presence of heart disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deluxe-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the features and the targets\n",
    "X = combineddata.drop(columns='absence or presence of heart disease', axis=1)\n",
    "Y = combineddata['absence or presence of heart disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "statutory-company",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2\n",
      "1      1\n",
      "2      2\n",
      "3      1\n",
      "4      2\n",
      "      ..\n",
      "562    2\n",
      "563    2\n",
      "564    2\n",
      "565    1\n",
      "566    1\n",
      "Name: absence or presence of heart disease, Length: 567, dtype: int64\n",
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    62.0  0.0  4.0     140.0  268.0  0.0      2.0    160.0    0.0      3.6   \n",
      "1    58.0  0.0  1.0     150.0  283.0  1.0      2.0    162.0    0.0      1.0   \n",
      "2    46.0  1.0  4.0     120.0  249.0  0.0      2.0    144.0    0.0      0.8   \n",
      "3    52.0  1.0  1.0     118.0  186.0  0.0      2.0    190.0    0.0      0.0   \n",
      "4    35.0  1.0  4.0     126.0  282.0  0.0      2.0    156.0    1.0      0.0   \n",
      "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
      "562  67.0  1.0  4.0     125.0  254.0  1.0      0.0    163.0    0.0      0.2   \n",
      "563  57.0  1.0  3.0     128.0  229.0  0.0      2.0    150.0    0.0      0.4   \n",
      "564  59.0  1.0  1.0     134.0  204.0  0.0      0.0    162.0    0.0      0.8   \n",
      "565  34.0  0.0  2.0     118.0  210.0  0.0      0.0    192.0    0.0      0.7   \n",
      "566  71.0  0.0  3.0     110.0  265.0  1.0      2.0    130.0    0.0      0.0   \n",
      "\n",
      "     slope   ca  thal  \n",
      "0      3.0  2.0   3.0  \n",
      "1      1.0  0.0   3.0  \n",
      "2      1.0  0.0   7.0  \n",
      "3      2.0  0.0   6.0  \n",
      "4      1.0  0.0   7.0  \n",
      "..     ...  ...   ...  \n",
      "562    2.0  2.0   7.0  \n",
      "563    2.0  1.0   7.0  \n",
      "564    1.0  2.0   3.0  \n",
      "565    1.0  0.0   3.0  \n",
      "566    1.0  1.0   3.0  \n",
      "\n",
      "[567 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(Y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lucky-florence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(567, 13) (453, 13) (114, 13)\n"
     ]
    }
   ],
   "source": [
    "# split to training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "meaning-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR - Accuracy on Training data:  0.8432671081677704\n",
      "LR - F1 score on Training data:  0.8637236084452976\n",
      "LR - Accuracy on Testing data:  0.8771929824561403\n",
      "LR - F1 score on Testing data:  0.8703703703703703\n"
     ]
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"LR - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"LR - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"LR - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"LR - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cross-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Accuracy on Training data:  0.8543046357615894\n",
      "SVM - F1 score on Training data:  0.8715953307392996\n",
      "SVM - Accuracy on Testing data:  0.8771929824561403\n",
      "SVM - F1 score on Testing data:  0.8653846153846154\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# define the SVM model with best parameters found via GridSearch\n",
    "svm_model = SVC(kernel='linear', C=10, class_weight='balanced')\n",
    "\n",
    "# training the model with training data\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = svm_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"SVM - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"SVM - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = svm_model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"SVM - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"SVM - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "operational-protection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB - Accuracy on Training data:  0.8653421633554084\n",
      "NB - F1 score on Training data:  0.8820116054158608\n",
      "NB - Accuracy on Testing data:  0.8596491228070176\n",
      "NB - F1 score on Testing data:  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "# define the Naive Bayes model with best hyperparameters found via GridSearch\n",
    "nb_model = GaussianNB(var_smoothing=1e-09)\n",
    "\n",
    "# training the model with training data\n",
    "nb_model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = nb_model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"NB - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"NB - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = nb_model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"NB - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"NB - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "conditional-pendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN - Accuracy on Training data:  0.8631346578366446\n",
      "ANN - F1 score on Training data:  0.8812260536398469\n",
      "ANN - Accuracy on Testing data:  0.8596491228070176\n",
      "ANN - F1 score on Testing data:  0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# ANN\n",
    "# define the ANN model with best hyperparameters found via GridSearch\n",
    "model = MLPClassifier(max_iter=10000,hidden_layer_sizes=(15, 10), activation='logistic', alpha=0.01)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"ANN - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"ANN - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"ANN - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"ANN - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bound-report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - Accuracy on Training data:  0.9977924944812362\n",
      "RF - F1 score on Training data:  0.9980353634577603\n",
      "RF - Accuracy on Testing data:  0.9210526315789473\n",
      "RF - F1 score on Testing data:  0.9174311926605504\n"
     ]
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "# define the RF model with best hyperparameters\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5)\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)\n",
    "training_data_f1_score = f1_score(Y_train, X_train_prediction)\n",
    "\n",
    "print(\"RF - Accuracy on Training data: \", training_data_accuracy)\n",
    "print(\"RF - F1 score on Training data: \", training_data_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)\n",
    "testing_data_f1_score = f1_score(Y_test, X_test_prediction)\n",
    "\n",
    "print(\"RF - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "print(\"RF - F1 score on Testing data: \", testing_data_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "valid-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN - Accuracy on Training data:  0.7527593818984547\n",
      "k-NN - F1 score on Training data:  0.7500690568991449\n",
      "k-NN - Accuracy on Testing data:  0.7280701754385965\n",
      "k-NN - F1 score on Testing data:  0.7279655468027514\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# Performing k-Nearest Neighbors model best hyperparameters found via GridSearch\n",
    "model = KNeighborsClassifier(n_neighbors=11, p=2, weights='uniform')\n",
    "\n",
    "# training the model with training data\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# accuracy and F1 score on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "\n",
    "print(\"k-NN - Accuracy on Training data: \", training_data_accuracy)\n",
    "\n",
    "training_f1_score = f1_score(Y_train, X_train_prediction, average='weighted')\n",
    "print(\"k-NN - F1 score on Training data: \", training_f1_score)\n",
    "\n",
    "# accuracy and F1 score on testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "\n",
    "testing_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "\n",
    "print(\"k-NN - Accuracy on Testing data: \", testing_data_accuracy)\n",
    "\n",
    "testing_f1_score = f1_score(Y_test, X_test_prediction, average='weighted')\n",
    "print(\"k-NN - F1 score on Testing data: \", testing_f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
